{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Fl5ZhMMK7Q"
      },
      "source": [
        "# TP1: FEATURE EXTRACTION & VISUALIZATION\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In this notebook, you will learn how to **extract radiomics features** and **visualize the important characteristics of the dataset**. We follow a typical data analysis pipeline.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/RRouhi/EPU-IA-2022/main/images/pipeline.png'/>\n",
        "\n",
        "First, download the necessary materials for the practical sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujZ5cuPNMrah"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/marsvn/PythonM2-jour3.git\n",
        "%cd PythonM2-jour3/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABi5RdLPMK7b"
      },
      "source": [
        "### Installation of dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irz6Seg-K4NI"
      },
      "outputs": [],
      "source": [
        "!pip install pyradiomics SimpleITK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RnP8vV2MK8W"
      },
      "source": [
        "## 1. Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmW-OCRfMK8Z"
      },
      "source": [
        "The dataset we will work on is a subset of the BraTS dataset (https://www.med.upenn.edu/cbica/brats2019/data.html). There are 10 patients in each of the Glioblastoma (`./data/preprocessed/GBM`) and Low-Grade Glioma (`./data/preprocessed/LGG`) classes. Each patient has five files: four MRI volumes of the brain under T1, T1-Gd, T2, and T2 Flair imaging modalities; and a tumour segmentation file. Let us start by considering **a single patient**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ-OOxTmKZ8o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "root_dir = './data/preprocessed'\n",
        "\n",
        "patient = 'GBM/TCGA-02-0037'\n",
        "patient_dir = os.path.join(root_dir, patient)\n",
        "patient_files = os.listdir(patient_dir)\n",
        "\n",
        "print(patient_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdWvy1TRMK8f"
      },
      "source": [
        "We will now visualise the files of this patient. In the following, the data is returned in the `sitk` format. `SimpleITK` is a python library for registration and segmentation of biomedical images. Two test cases will be loaded and and saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ojCF_RIZKZ8q"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "\n",
        "def load_nii_volume_as_array(filename, with_header=False):\n",
        "    \"\"\"\n",
        "    load NIfTI image into numpy array with axis order of [z,y,x]\n",
        "    The output array shape is like [Depth, Height, Width]\n",
        "    :param filename: the input file name, should be *.nii or *.nii.gz\n",
        "    :param with_header: return header information\n",
        "    :return: a numpy data array or numpy data array with header if set to True\n",
        "    \"\"\"\n",
        "    img = sitk.ReadImage(filename)\n",
        "    data = sitk.GetArrayFromImage(img)\n",
        "\n",
        "    if with_header:\n",
        "        origin, spacing, direction = img.GetOrigin(), img.GetSpacing(), img.GetDirection()\n",
        "        return data, (origin, spacing, direction)\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "volume = load_nii_volume_as_array(os.path.join(patient_dir, patient_files[0]))\n",
        "print(volume.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gftAOk0zKZ8s"
      },
      "source": [
        "There are $155$ slices in the volume, where each slice is $240\\times240$px image. Let's visualise some of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdwUikCyKZ8s"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=5, nrows=4, figsize=(15, 10))\n",
        "for i, img in enumerate(volume[::8]):\n",
        "    axes.ravel()[i].set_title('Slice: %d' % (8 * i))\n",
        "    axes.ravel()[i].imshow(img, cmap='Greys_r')\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaYdzBgsKZ8t"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Visualize a single slice for each imaging modality and the segmentation mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAm1xPakKZ8t"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=5, figsize=(10, 10))\n",
        "\n",
        "for i, patient_file in enumerate(patient_files):\n",
        "    volume = load_nii_volume_as_array(\"\"\"CompleteHere\"\"\")\n",
        "    axes[i].imshow(volume[80], cmap='Greys_r')\n",
        "    axes[i].set_title(patient_file.split('_')[-1].split('.')[0])\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq0zvgupKZ8t"
      },
      "source": [
        "## 2. Normalising data\n",
        "\n",
        "To stabilise the downstream feature extraction and analysis, we first normalise the data. For input image $X$, we create normalised image $Z$ by normalising each pixel $x_{ij}$ according to,\n",
        "\n",
        "$$z_{ij} = \\frac{x_{ij} - \\mu_X}{\\sigma_X}.$$\n",
        "\n",
        "Because of the abundance of background values in each volume, we compute $\\mu_X$ and $\\sigma_X$ only over the pixels of $X$ above a certain threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AxvfCt_MK8l"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "\n",
        "def set_header_information(array, header):\n",
        "    \"\"\"\n",
        "    Function to set header information to an array.\n",
        "    :param array: array to set the header\n",
        "    :param header: header information will be a tuple with (origin, spacing, direction)\n",
        "    :return: an image in sitk format\n",
        "    \"\"\"\n",
        "    img = sitk.GetImageFromArray(array)\n",
        "    img.SetOrigin(header[0])\n",
        "    img.SetSpacing(header[1])\n",
        "    img.SetDirection(header[2])\n",
        "    return img\n",
        "\n",
        "def zscore_normalize(patient, image_type):\n",
        "    \"\"\"\n",
        "    Function to Z-Score normalize an image from an image filepath. It will normalize the target\n",
        "    image by subtracting the mean of the whole brain and dividing by the standard deviation.\n",
        "    :param img_path: target MR brain image path\n",
        "    :param mask: brain mask path for img\n",
        "    :return: Normalized image in sitk format\n",
        "    \"\"\"\n",
        "\n",
        "    img_path = glob(os.path.join(root_dir, patient, f'*{image_type}.nii.gz'))[0]\n",
        "    img_data, header = load_nii_volume_as_array(img_path, with_header=True)\n",
        "    mask = (img_data > img_data.mean()) == 1  # force the mask to be logical type\n",
        "\n",
        "    mean = img_data[mask].mean()\n",
        "    std = img_data[mask].std()\n",
        "\n",
        "    normalized_data = (img_data - mean) / std\n",
        "    normalized = set_header_information(normalized_data, header)\n",
        "\n",
        "    return normalized\n",
        "\n",
        "normalised_image = zscore_normalize(patient, 't1')\n",
        "normalised_volume = sitk.GetArrayFromImage(normalised_image)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 3))\n",
        "\n",
        "def plot_histogram(ax, volume, title):\n",
        "    ax.hist(volume.flatten(), color='gray')\n",
        "    ax.set_xlabel('intensity')\n",
        "    ax.set_yscale('log')\n",
        "    ax.set_title(title)\n",
        "\n",
        "plot_histogram(axes[0], volume, 'unnormalised')\n",
        "plot_histogram(axes[1], normalised_volume, 'normalised')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9KeJyZpKZ8v"
      },
      "source": [
        "### Extract mask information\n",
        "\n",
        "If we visualise a given slice of any mask volume, we see that it is in fact a multi-class image, where different values indicate different tumour regions: enhancing tumour (ET), peritumoral edema (ED), necrosis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2cSLdABKZ8w"
      },
      "outputs": [],
      "source": [
        "mask_path = glob(os.path.join(root_dir, patient, '*seg*'))[0]\n",
        "mask, header = load_nii_volume_as_array(mask_path, with_header=True)\n",
        "\n",
        "plt.imshow(mask[96])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgGgz07cKZ8w"
      },
      "source": [
        "From this multi-class mask, we can derive the regions as separate binary masks. We define a special purpose function to extract each mask region as a separate binary mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-AWyp-mKZ8w"
      },
      "outputs": [],
      "source": [
        "def get_masks(patient):\n",
        "    \"\"\"\n",
        "    Function to read one subject's mask from the general input directory specified by patient ID\n",
        "    :param patient: the patient ID\n",
        "    :return: a dict for the 'seg' with key as type of seg and value as nD array. For image a nD array\n",
        "    \"\"\"\n",
        "\n",
        "    mask_path = glob(os.path.join(root_dir, patient, '*seg*'))[0]\n",
        "    mask, header = load_nii_volume_as_array(mask_path, with_header=True)\n",
        "\n",
        "    label_full = mask.copy()\n",
        "    label_full[mask != 0] = 1        # take all regions\n",
        "\n",
        "    label_nec = mask.copy()\n",
        "    label_nec[mask != 1] = 0         # necrosis only\n",
        "\n",
        "    label_core = mask.copy()\n",
        "    label_core[mask == 2] = 0        # no edema\n",
        "    label_core[label_core != 0] = 1  # keep necrosis, ET, NET i.e. tumor core\n",
        "\n",
        "    label_et = mask.copy()\n",
        "    label_et[mask != 4] = 0          # ET only\n",
        "    label_et[mask == 4] = 1\n",
        "\n",
        "    all_masks = {\n",
        "        'label_full' : set_header_information(label_full, header),\n",
        "        'label_nec' : set_header_information(label_nec, header),\n",
        "        'label_core' : set_header_information(label_core, header),\n",
        "        'label_et' : set_header_information(label_et, header)\n",
        "    }\n",
        "\n",
        "    return all_masks\n",
        "\n",
        "all_masks = get_masks(patient)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=4, figsize=(15, 5))\n",
        "\n",
        "for ax, mask_key, mask_volume in zip(axes, all_masks.keys(), all_masks.values()):\n",
        "    ax.set_title(mask_key)\n",
        "    ax.imshow(sitk.GetArrayFromImage(mask_volume)[96], cmap='Greys_r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL_MOd6KMK8v"
      },
      "source": [
        "**Exercise:** Replace the expression `CompleteHere` in the following script to:\n",
        "- load images and segmentations from the two patients\n",
        "- apply normalisation to MRI images\n",
        "- save the normalised images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXf_RjHiKZ8x"
      },
      "outputs": [],
      "source": [
        "#@title Exercise 2\n",
        "\"\"\"\n",
        ">>> Preprocess patient 1\n",
        "\"\"\"\n",
        "\n",
        "patient1 = 'GBM/TCGA-02-0037/'\n",
        "\n",
        "# normalise volumes\n",
        "patient1_t1 = zscore_normalize(patient1, 't1')\n",
        "patient1_t1ce = zscore_normalize(patient1, 't1ce')\n",
        "patient1_t2 = zscore_normalize(patient1, 't2')\n",
        "patient1_flair = zscore_normalize(patient1, 'flair')\n",
        "\n",
        "# Write normalised volumes\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient1_t1_normalize.nii.gz')\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient1_t1ce_normalize.nii.gz')\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient1_t2_normalize.nii.gz')\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient1_flair_normalize.nii.gz')\n",
        "\n",
        "# Derive masks\n",
        "patient1_masks = get_masks(patient1)\n",
        "\n",
        "# Write masks\n",
        "sitk.WriteImage(patient1_masks['label_full'], 'patient1_seg_label_full.nii.gz')\n",
        "sitk.WriteImage(patient1_masks['label_nec'], 'patient1_seg_label_nec.nii.gz')\n",
        "sitk.WriteImage(patient1_masks['label_core'], 'patient1_seg_label_core.nii.gz')\n",
        "sitk.WriteImage(patient1_masks['label_et'], 'patient1_seg_label_et.nii.gz')\n",
        "\n",
        "\"\"\"\n",
        ">>> Preprocess patient 2\n",
        "\"\"\"\n",
        "\n",
        "patient2 = 'LGG/TCGA-CS-5396/'\n",
        "\n",
        "# Normalise volumes\n",
        "patient2_t1 = zscore_normalize(patient2, 't1')\n",
        "patient2_t1ce = zscore_normalize(patient2, 't1ce')\n",
        "patient2_t2 = zscore_normalize(patient2, 't2')\n",
        "patient2_flair = zscore_normalize(patient2, 'flair')\n",
        "\n",
        "# Write normalised volumes\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient2_t1_normalize.nii.gz')\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient2_t1ce_normalize.nii.gz')\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient2_t2_normalize.nii.gz')\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient2_flair_normalize.nii.gz')\n",
        "\n",
        "# Derive masks\n",
        "patient2_masks = get_masks(patient2)\n",
        "\n",
        "# Write masks\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient2_seg_label_full.nii.gz')\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient2_seg_label_nec.nii.gz')\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient2_seg_label_core.nii.gz')\n",
        "sitk.WriteImage(\"\"\"CompleteHere\"\"\", 'patient2_seg_label_et.nii.gz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gczujo3tMK86"
      },
      "source": [
        "## 3. Feature extraction\n",
        "\n",
        "Now that we have prepared our image inputs, we need to define the parameters and instantiate the extractor. We use the default settings of the extractor. Let us extract features for patient 1, under the t1 modality, for the full tumour region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSIoiLJjMK9P"
      },
      "outputs": [],
      "source": [
        "from radiomics import featureextractor  # This module is used for interaction with pyradiomics\n",
        "\n",
        "# Instantiate the extractor\n",
        "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
        "\n",
        "imagePath = 'patient1_t1_normalize.nii.gz'\n",
        "maskPath = 'patient1_seg_label_full.nii.gz'\n",
        "\n",
        "result = extractor.execute(imagePath, maskPath)\n",
        "print(result.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KWgzJT3MK_M"
      },
      "source": [
        "As you can see, Pyradiomics returns an ordered dictionary that is visually not very pleasant. We can instead turn this result into a `pandas` format. The keys in the dictionary will be used as the index (labels for the rows), with the values of the features as the values in the rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82AK29bsMK_N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.Series(result)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPo7haYZMK_e"
      },
      "source": [
        "### Process all\n",
        "\n",
        "Now we will use a loop to extract a set of features for our two patients with each of their segmentations. The idea is to loop over each image the associated segmentations. We construct a `pandas.DataFrame` object to list each combination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GxWJyyUKZ80"
      },
      "outputs": [],
      "source": [
        "image_names = sorted(glob('patient1*normalize*'))\n",
        "mask_names = sorted(glob('patient1_seg*'))\n",
        "\n",
        "index = pd.MultiIndex.from_product([image_names, mask_names], names = ['Image', 'Segmentation'])\n",
        "df_patient1 = pd.DataFrame(index=index).reset_index()\n",
        "\n",
        "image_names = sorted(glob('patient2*normalize*'))\n",
        "mask_names = sorted(glob('patient2_seg*'))\n",
        "\n",
        "index = pd.MultiIndex.from_product([image_names, mask_names], names = ['Image', 'Segmentation'])\n",
        "df_patient2 = pd.DataFrame(index=index).reset_index()\n",
        "\n",
        "database_df = pd.concat([df_patient1, df_patient2]).reset_index(drop=True)\n",
        "database_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfSpcnV6KZ80"
      },
      "source": [
        "Now we can iterate over each row of our `pandas.DataFrame` and extract features for each combination of modality and tumour interest region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLEMvYXnMK_s"
      },
      "outputs": [],
      "source": [
        "from radiomics import featureextractor\n",
        "\n",
        "paramPath = os.path.join('exampleSettings', 'Params.yaml')\n",
        "extractor = featureextractor.RadiomicsFeatureExtractor(paramPath)\n",
        "\n",
        "results_extraction = pd.DataFrame()\n",
        "for row_idx, row in database_df.iterrows():\n",
        "    print('process:'  '   ----   ' 'Image: ', row['Image'], ' Segmentation: ', row['Segmentation'])\n",
        "    result_extraction = pd.Series(extractor.execute(row['Image'], row['Segmentation']))\n",
        "    feature_vector = pd.concat([pd.Series(row), result_extraction])\n",
        "    feature_vector.name = row_idx\n",
        "    results_extraction = results_extraction.join(feature_vector, how='outer')\n",
        "\n",
        "# Transpose DataFrame to have one row per analysis\n",
        "results_extraction = results_extraction.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzb-tgTgKZ81"
      },
      "source": [
        "The result consists of a table where each row corresponds to an modality/interest region pair, and each column is a radiomics feature. We can print a few rows using `pd.DataFrame.head()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynx9K8h8MK_1"
      },
      "outputs": [],
      "source": [
        "results_extraction.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VuBHlZ7MLAB"
      },
      "source": [
        "### Compare feature signatures\n",
        "\n",
        "Now, let's compare the feature \"signatures\" for our two patients. Because we would like to plot the feature vectors, we will create `numpy` arrays for those features with prefix `original_` (i.e. excluding meta-features). We begin by extracting the relevant parts of `results_extraction` above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H6MofSDLTZo"
      },
      "outputs": [],
      "source": [
        "# Extract patient and modality identifiers\n",
        "patient = results_extraction['Image'].str.split('_').str[0]\n",
        "sequence = results_extraction['Image'].str.split('_').str[1]\n",
        "\n",
        "# Extract segmentation type\n",
        "segtype = results_extraction['Segmentation'].str.split('_').str[-1].str.split('.').str[0]\n",
        "\n",
        "# Extract non-meta features\n",
        "feature_columns = [col for col in results_extraction if col.startswith('original')]\n",
        "\n",
        "dataframe_cleaned = results_extraction[feature_columns]\n",
        "dataframe_cleaned.insert(0, 'patient', patient)\n",
        "dataframe_cleaned.insert(1, 'sequence', sequence)\n",
        "dataframe_cleaned.insert(2, 'segmentation', segtype)\n",
        "\n",
        "dataframe_cleaned.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tehgz6HpMLAT"
      },
      "source": [
        "**Exercise:** Complete the following script to:\n",
        "- extract the feature signatures for a given modality/region combination by slicing `dataframe_cleaned`:\n",
        "- plot the two feature vectors and their difference.\n",
        "\n",
        "Notes:\n",
        "- Feature values have a wide range of magnitudes and will be plotted on a log scale. You can have fun and change the input modality or the segmentation type.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_jOGAHfMLAV"
      },
      "outputs": [],
      "source": [
        "#@title Exercise 3\n",
        "modality = '''CompleteHere'''\n",
        "seg = '''CompleteHere'''\n",
        "features_p1 =  dataframe_cleaned.iloc['''CompleteHere'''].to_numpy()\n",
        "features_p2 =  dataframe_cleaned.iloc['''CompleteHere'''].to_numpy()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, sharex=True, squeeze=True, figsize=(20, 10))\n",
        "\n",
        "axes[0].plot('''CompleteHere''', label=f\"features from patient 1 for the segmentation {seg} in modality {modality}\", color='red')\n",
        "axes[0].plot('''CompleteHere''', label=f\"features from patient 2 for the segmentation {seg} in modality {modality}\", color='green')\n",
        "axes[0].set_yscale('symlog')\n",
        "axes[0].set_ylabel('symlog')\n",
        "axes[0].set_xlabel('feature id')\n",
        "axes[0].set_xticklabels(feature_columns, rotation='vertical')\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot('''CompleteHere''' - features_p2_t1_full)\n",
        "axes[1].set_yscale('symlog')\n",
        "axes[1].set_ylabel('symlog')\n",
        "axes[1].set_xlabel('feature id')\n",
        "axes[1].set_xticks(range(len(features_p1_t1_full)))\n",
        "axes[1].set_xticklabels('''CompleteHere''', rotation=90)\n",
        "axes[1].set_title('''CompleteHere''')\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2kRLi2qMLAr"
      },
      "source": [
        "## 4. Exploring and Visualizing Data\n",
        "\n",
        "The first step in applying machine learning is to understand the data, so as to be able to identify a good target to learn, as well as an appropriate learning algorithm among many alternatives.\n",
        "\n",
        "The analysis above has been applied on two patients only. Since our time in this practical session is limited, the features on the entire BraTS dataset has been extracted into a csv file located at `./data/radiomics_analysis_cleaned.csv`. This file contains one row per patient per input modality (T1, T1ce, T2, flair) per type of tumor ROI ($4\\times4=16$ rows per patient). With the feaures from the full cohort, we can begin to explore the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_l2SfxwMLAx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "path_dataset = './data/radiomics_analysis_cleaned.csv'\n",
        "\n",
        "data = pd.read_csv(path_dataset)\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUaUlXE7MLA3"
      },
      "source": [
        "We can generate a full `pandas.DataFrame` which represents all the features for a patient. This gives $16\\times100 = 1600$ featues per patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vljErfNlLjvG"
      },
      "outputs": [],
      "source": [
        "full_features_df = data.pivot_table(index=['patient', 'label'],\n",
        "                                    columns=['sequence', 'segmentation'],\n",
        "                                    values=data.columns[4:])\n",
        "full_features_df.columns = ['_'.join(col).strip() for col in full_features_df.columns.values]\n",
        "full_features_df.reset_index(level=1, inplace=True)\n",
        "\n",
        "label_counts = full_features_df['label'].value_counts()\n",
        "\n",
        "print('Patients per disease class: %d HGG, %d LGG' % (label_counts.HGG, label_counts.LGG))\n",
        "print('Numbers of features: %d' % (len(full_features_df.columns) -1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPvaNgEtMLBJ"
      },
      "source": [
        "### Pairwise joint distributions\n",
        "\n",
        "We can see the join distribution of any pair of columns/attributes/variables/features by using the pairplot function offered by `Seaborn`, which is a plotting library based on `Matplotlib`. We do this for the first 5 features. Each datapoint is a patient and the colour indicates the disease class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYJ61n3WMLBO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# filter one sequence type and a segmentation type (you can change the sequence type and segmentation type)\n",
        "d = data[(data['sequence']=='t1ce')  & (data['segmentation']=='full')].iloc[:, 3:9]\n",
        "\n",
        "sns.pairplot(d, hue='label', height=2.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44IbRa5jZBUH"
      },
      "source": [
        "#### Interpretation\n",
        "\n",
        "We can observe in the plots that some pairs of features yield a high degree of discrimination between LGG (in orange) and HGG (in blue) patients.\n",
        "For instance, the plot in the second row, first column, between the features 10Percentile (10th percentile of image intensities) and 90Percentile (idem with 90th) appears to cluster each cancer subtypes into roughly distinct clusters.\n",
        "\n",
        "In these 2D feature subspaces, a simple line separating the two classes would form the basis of a decision system for classifying an MRI. Multi-dimensional models, applied on many hundreds of features, essentially perform the same method, by fitting a *hyperplane* such to best separate the datapoints from each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e2cFiE-MLBU"
      },
      "source": [
        "### Plot features' dependency as a heatmap\n",
        "\n",
        "Plotting all pairwise distributions may still be hard to interpret when we have a lot of variables in the dataset. Instead, we can just plot the correlation matrix to quantify the linear relationship between variables.\n",
        "\n",
        "A heat map uses colour to depict the correlation of each feature with every other feature. A heatmap may furthremore be clustered (unsupervised machine learning) to show groupings of similar features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xEdc4yjMLBY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# filter one sequence type and a segmentation type (you can change the sequence type and segmentation type)\n",
        "d = data[(data['sequence']=='t1ce')  & (data['segmentation']=='full')].iloc[:, 3:] # the full feature one is too big\n",
        "\n",
        "# create the correlation matrix\n",
        "corr = d.select_dtypes(include=['number']).corr()\n",
        "\n",
        "# Set up the matplotlib figure, make it big!\n",
        "f, ax = plt.subplots(figsize=(15, 10))\n",
        "\n",
        "# Draw the heatmap using seaborn\n",
        "sns.heatmap(corr, vmax=.8, square=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcqK1vLyMLBg"
      },
      "source": [
        "### Cluster the heatmap\n",
        "\n",
        "Though useful, heatmaps tell a much better story if the features are clustered. Here we will take a smaller subset of the features and cluster them. In this dendrogram, there are 2 major groups, and many smaller groupings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EC3ygNEfL4To"
      },
      "outputs": [],
      "source": [
        "# Choose a subset of features for clustering\n",
        "dd = d.iloc[:,3:50]\n",
        "\n",
        "pp = sns.clustermap(dd.corr(), linewidths=.5, figsize=(13,13))\n",
        "_ = plt.setp(pp.ax_heatmap.get_yticklabels(), rotation=0)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}